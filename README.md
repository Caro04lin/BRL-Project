# Upper Limb Exoskeleton Real-Time Detection

This project provide four **real-time human intention recognition system** for an upper limb exoskeleton. 
Each system include a pre-trained model **YOLO** model for detecting painting tools and hands. MoViNet was selected to recognize user actions based on video frames. Multiple deep learning architectures


including the Long Short-Term Memory (LSTM), Gated Recurrent Units (GRU), Convolutional Neural Network–Gated Recurrent Unit (CNN-GRU) and Temporal Convolutional Network (TCN) models, were developed, trained, and compared to get the most accurate model for real-time detection of user intent during painting tasks, including the tool being used and the current task phase. 



the models, including the Long Short-Term Memory (LSTM), Gated Recurrent Units (GRU), Convolutional Neural Network–Gated Recurrent Unit (CNN-GRU), and Temporal Convolutional Network (TCN), were developed and compared to each other. 

