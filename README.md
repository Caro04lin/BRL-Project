# Upper Limb Exoskeleton Real-Time Detection

This project provide four **real-time human intention recognition system** for an upper limb exoskeleton. 
Each system include a pre-trained model **YOLO** model for detecting painting tools and hands. MoViNet was selected to recognize user actions based on both video frames. 
The

and IMU data, MoViNet were combined either with the Long Short-Term Memory (LSTM), the Gated Recurrent Units (GRU), the Convolutional Neural Network–Gated Recurrent Unit (CNN-GRU), and the Temporal Convolutional Network (TCN) models. 


the models, including the Long Short-Term Memory (LSTM), Gated Recurrent Units (GRU), Convolutional Neural Network–Gated Recurrent Unit (CNN-GRU), and Temporal Convolutional Network (TCN), were developed and compared to each other. 

